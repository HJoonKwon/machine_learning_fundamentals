{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMgpCF5XwWnpEeSfOJJp9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HJoonKwon/ml_fundamentals/blob/main/NaiveBayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes Algorithm \n",
        "\n",
        "- Supervised learning (We need training data) \n",
        "- For classification \n",
        "- Based on Bayes' Theorem\n",
        "- \"Naive\" means we assume features are independent to each other. \n",
        "\n",
        "### How does it work?\n",
        "- Based on Bayes' theorm, we can calculate posterior probability using prior proabibility, likelihood, and evidence(or marginal probability).\n",
        " $$P(A|B) =  \\frac{P(B|A)P(A)}{P(B)} $$\n",
        "- We can just apply the Bayes' theorem to prediction for the probability of the output(classification or regression). Let's assume that the training data has ```n``` number of features, and we want to predict the probability of ```y``` given ```X```. Then,\n",
        " $$P(y|X) = P(y|x_1, ..., x_n) = \\frac{P(x_1, .., x_n|y)P(y)}{P(x_1, ..., x_n)}  = \\frac{P(x_1|y)...P(x_n|y)P(y)}{P(x_1)...P(x_n)}$$ \n",
        "\n",
        " ### What kind of data can it handle?\n",
        " - Continuous (Gaussian Naive Bayes)\n",
        " - Discrete (Binary/Multinomial Naive Bayes) "
      ],
      "metadata": {
        "id": "GGRwEMw9_73Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "NSx5I2LAHWjg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Prepare for the dataset \n",
        "- We are going to use the breast cancer dataset provided by scikit-learn. \n",
        "- We can see that all features are continuous, so the Gaussian Naive Bayes would be our choice. "
      ],
      "metadata": {
        "id": "6pf4MoTgG82K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dV9ac0Xm88N5"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer() "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['data'].shape)\n",
        "print(data['feature_names'])\n",
        "print(data['data'][0])\n",
        "print(data['target_names'])\n",
        "print(data['target'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTXqDvrsHlIV",
        "outputId": "adf7d9e5-900b-41f9-ee33-2e5523ae1203"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            " 4.601e-01 1.189e-01]\n",
            "['malignant' 'benign']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Preprocessing the data"
      ],
      "metadata": {
        "id": "7ByagjEILiBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler() \n",
        "X = data['data']\n",
        "y = data['target']\n",
        "X = scaler.fit_transform(X)\n",
        "train_X, train_y, test_X, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jhcW00gKbot",
        "outputId": "fff4cdf9-3741-4ada-a5a2-3c8bda1b0b88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.09706398 -2.07333501  1.26993369  0.9843749   1.56846633  3.28351467\n",
            "  2.65287398  2.53247522  2.21751501  2.25574689  2.48973393 -0.56526506\n",
            "  2.83303087  2.48757756 -0.21400165  1.31686157  0.72402616  0.66081994\n",
            "  1.14875667  0.90708308  1.88668963 -1.35929347  2.30360062  2.00123749\n",
            "  1.30768627  2.61666502  2.10952635  2.29607613  2.75062224  1.93701461]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Define helper functions "
      ],
      "metadata": {
        "id": "7qcd_-aALmlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_mean_var():\n",
        "  return \n",
        "\n",
        "def gaussian_log_likelihood():\n",
        "  return "
      ],
      "metadata": {
        "id": "KCt4p4grLm0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Gaussian Naive Bayes Implementation "
      ],
      "metadata": {
        "id": "HfDgmAo1Lr-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianNaiveBayes():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def calc_prior(self):\n",
        "    pass\n",
        "\n",
        "  def calc_posterior(self):\n",
        "    pass\n",
        "  \n",
        "  def fit(self):\n",
        "    pass \n",
        "  \n",
        "  def predict(self):\n",
        "    pass "
      ],
      "metadata": {
        "id": "hEFTGEWVLvll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References \n",
        "- https://medium.com/@rangavamsi5/na%C3%AFve-bayes-algorithm-implementation-from-scratch-in-python-7b2cc39268b9\n",
        "- https://towardsdatascience.com/implementing-naive-bayes-algorithm-from-scratch-python-c6880cfc9c41"
      ],
      "metadata": {
        "id": "did_kqUbCDI_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5sC5j2MsIFV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}