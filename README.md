# Overview
To understand fast growing technologies in machine learning, we need to understand the fundamentals first. Hence, I reimplemented machine learning fundamental algorithms from scratch using Numpy with simple examples on the Jupyter notebook. Although essential mathematical equations needed to implement the algorithms are included on the notebooks, some of the detailed concepts are simplified or skipped not to focus on math itself too much. The core of the algorithms are written as Python scripts, and they are imported and used for test on the notebooks.   

# Keywords checklist  
- [x] Linear Regression 
- [x] Logistic Regression
- [x] K-Nearest Neighbors 
- [x] K-Means Clustering 
- [ ] Decision Trees 
  - [ ] Random Forest 
  - [ ] Bagging
  - [ ] Boosting
  - [ ] Pasting 
- [x] Naive Bayes 
- [x] Support Vector Machine
- [ ] Dimensionality Reduction
  - [ ] Principal Component Analysis 
  - [ ] Locally Linear Embedding 
- [x] Neural Network 
  - [x] Gradient Descent
  - [ ] Regularization 
  - [ ] Optimizers
  - [ ] Batch Normalization 
  - [ ] Weight Initialization 
  - [x] Activation functions

## References 
I mainly referred to CS230(2018), CS229(2018), and other great articles on Medium. Each notebook has its corresponding references written on the bottom.
